{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "696e37fe",
   "metadata": {},
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8281b6f8",
   "metadata": {},
   "source": [
    "# Machine Learning in Python - Project 1\n",
    "\n",
    "Due Friday, Feb 28th by 4 pm.\n",
    "\n",
    "*Include contributors names in notebook metadata or here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821233d2",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "*Install any packages here, define any functions if neeed, and load data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e1ba94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any additional libraries or submodules below\n",
    "\n",
    "# Data libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotting defaults\n",
    "plt.rcParams['figure.figsize'] = (8,5)\n",
    "plt.rcParams['figure.dpi'] = 80\n",
    "\n",
    "# sklearn modules\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca1462b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/AwuoeZYC/Project_1/main/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62abe5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>ADAS13.bl</th>\n",
       "      <th>ADAS13.m24</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DX.bl</th>\n",
       "      <th>PTGENDER</th>\n",
       "      <th>PTEDUCAT</th>\n",
       "      <th>PTETHCAT</th>\n",
       "      <th>PTRACCAT</th>\n",
       "      <th>PTMARRY</th>\n",
       "      <th>APOE4</th>\n",
       "      <th>Ventricles</th>\n",
       "      <th>Hippocampus</th>\n",
       "      <th>WholeBrain</th>\n",
       "      <th>Entorhinal</th>\n",
       "      <th>Fusiform</th>\n",
       "      <th>MidTemp</th>\n",
       "      <th>ICV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>31.00</td>\n",
       "      <td>37.67</td>\n",
       "      <td>81.3</td>\n",
       "      <td>AD</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>Not Hisp/Latino</td>\n",
       "      <td>White</td>\n",
       "      <td>Married</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84599.0</td>\n",
       "      <td>5319.0</td>\n",
       "      <td>1129834.0</td>\n",
       "      <td>1791.0</td>\n",
       "      <td>15506.0</td>\n",
       "      <td>18422.0</td>\n",
       "      <td>1.920691e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>14.67</td>\n",
       "      <td>11.00</td>\n",
       "      <td>73.7</td>\n",
       "      <td>CN</td>\n",
       "      <td>Male</td>\n",
       "      <td>16</td>\n",
       "      <td>Not Hisp/Latino</td>\n",
       "      <td>White</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34062.0</td>\n",
       "      <td>7075.0</td>\n",
       "      <td>1116633.0</td>\n",
       "      <td>4433.0</td>\n",
       "      <td>24788.0</td>\n",
       "      <td>21614.0</td>\n",
       "      <td>1.640766e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>25.67</td>\n",
       "      <td>22.67</td>\n",
       "      <td>80.4</td>\n",
       "      <td>LMCI</td>\n",
       "      <td>Female</td>\n",
       "      <td>13</td>\n",
       "      <td>Not Hisp/Latino</td>\n",
       "      <td>White</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39826.0</td>\n",
       "      <td>5348.0</td>\n",
       "      <td>927510.0</td>\n",
       "      <td>2277.0</td>\n",
       "      <td>17963.0</td>\n",
       "      <td>17802.0</td>\n",
       "      <td>1.485834e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>40.33</td>\n",
       "      <td>47.00</td>\n",
       "      <td>75.4</td>\n",
       "      <td>AD</td>\n",
       "      <td>Male</td>\n",
       "      <td>10</td>\n",
       "      <td>Hisp/Latino</td>\n",
       "      <td>More than one</td>\n",
       "      <td>Married</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25704.0</td>\n",
       "      <td>6729.0</td>\n",
       "      <td>875798.0</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>12063.0</td>\n",
       "      <td>15374.0</td>\n",
       "      <td>1.353519e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>24.33</td>\n",
       "      <td>30.33</td>\n",
       "      <td>73.9</td>\n",
       "      <td>AD</td>\n",
       "      <td>Female</td>\n",
       "      <td>12</td>\n",
       "      <td>Not Hisp/Latino</td>\n",
       "      <td>White</td>\n",
       "      <td>Married</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26820.0</td>\n",
       "      <td>5485.0</td>\n",
       "      <td>1033542.0</td>\n",
       "      <td>2676.0</td>\n",
       "      <td>16761.0</td>\n",
       "      <td>19741.0</td>\n",
       "      <td>1.471184e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RID  ADAS13.bl  ADAS13.m24   AGE DX.bl PTGENDER  PTEDUCAT         PTETHCAT  \\\n",
       "1    3      31.00       37.67  81.3    AD     Male        18  Not Hisp/Latino   \n",
       "2    5      14.67       11.00  73.7    CN     Male        16  Not Hisp/Latino   \n",
       "3    6      25.67       22.67  80.4  LMCI   Female        13  Not Hisp/Latino   \n",
       "4    7      40.33       47.00  75.4    AD     Male        10      Hisp/Latino   \n",
       "5   10      24.33       30.33  73.9    AD   Female        12  Not Hisp/Latino   \n",
       "\n",
       "        PTRACCAT  PTMARRY  APOE4  Ventricles  Hippocampus  WholeBrain  \\\n",
       "1          White  Married    1.0     84599.0       5319.0   1129834.0   \n",
       "2          White  Married    0.0     34062.0       7075.0   1116633.0   \n",
       "3          White  Married    0.0     39826.0       5348.0    927510.0   \n",
       "4  More than one  Married    1.0     25704.0       6729.0    875798.0   \n",
       "5          White  Married    1.0     26820.0       5485.0   1033542.0   \n",
       "\n",
       "   Entorhinal  Fusiform  MidTemp           ICV  \n",
       "1      1791.0   15506.0  18422.0  1.920691e+06  \n",
       "2      4433.0   24788.0  21614.0  1.640766e+06  \n",
       "3      2277.0   17963.0  17802.0  1.485834e+06  \n",
       "4      2050.0   12063.0  15374.0  1.353519e+06  \n",
       "5      2676.0   16761.0  19741.0  1.471184e+06  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data in easyshare.csv\n",
    "d = pd.read_csv(f\"{url}adnidata.csv\", index_col=0)\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3685a633",
   "metadata": {},
   "outputs": [],
   "source": [
    "#引用workshop中的代码\n",
    "def model_fit(m, X, y, plot = False):\n",
    "    \"\"\"Returns the mean squared error, root mean squared error and R^2 value of a fitted model based \n",
    "    on provided X and y values.\n",
    "    \n",
    "    Args:\n",
    "        m: sklearn model object\n",
    "        X: model matrix to use for prediction\n",
    "        y: outcome vector to use to calculating rmse and residuals\n",
    "        plot: boolean value, should fit plots be shown \n",
    "    \"\"\"\n",
    "    \n",
    "    y_hat = m.predict(X)\n",
    "    MSE = mean_squared_error(y, y_hat)\n",
    "    RMSE = np.sqrt(mean_squared_error(y, y_hat))\n",
    "    Rsqr = r2_score(y, y_hat)\n",
    "    \n",
    "    Metrics = (round(MSE, 4), round(RMSE, 4), round(Rsqr, 4))\n",
    "    \n",
    "    res = pd.DataFrame(\n",
    "        data = {'y': y, 'y_hat': y_hat, 'resid': y - y_hat}\n",
    "    )\n",
    "    \n",
    "    if plot:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        plt.subplot(121)\n",
    "        sns.lineplot(x='y', y='y_hat', color=\"grey\", data =  pd.DataFrame(data={'y': [min(y),max(y)], 'y_hat': [min(y),max(y)]}))\n",
    "        sns.scatterplot(x='y', y='y_hat', data=res).set_title(\"Observed vs Fitted values\")\n",
    "        \n",
    "        plt.subplot(122)\n",
    "        sns.scatterplot(x='y_hat', y='resid', data=res).set_title(\"Fitted values vs Residuals\")\n",
    "        plt.hlines(y=0, xmin=np.min(y), xmax=np.max(y), linestyles='dashed', alpha=0.3, colors=\"black\")\n",
    "        \n",
    "        plt.subplots_adjust(left=0.0)\n",
    "        \n",
    "        plt.suptitle(\"Model (MSE, RMSE, Rsq) = \" + str(Metrics), fontsize=14)\n",
    "        plt.show()\n",
    "    \n",
    "    return MSE, RMSE, Rsqr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28603fe7",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "*This section should include a brief introduction to the task and the data (assume this is a report you are delivering to a professional body (e.g. Alzheimer's Association, Health Institutes and/or other Charities on dementia and ageing).*\n",
    "\n",
    "*Briefly outline the approaches being used and the conclusions that you are able to draw.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4bc461",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis and Feature Engineering\n",
    "\n",
    "*Include a detailed discussion of the data with a particular emphasis on the features of the data that are relevant for the subsequent modeling. Including visualizations of the data is strongly encouraged - all code and plots must also be described in the write up. Think carefully about whether each plot needs to be included in your final draft and the appropriate type of plot and summary for each variable type - your report should include figures but they should be as focused and impactful as possible.*\n",
    "\n",
    "*You should also split your data into training and testing sets, ideally before you look to much into the features and relationships with the target*\n",
    "\n",
    "*Additionally, this section should also implement and describe any preprocessing / feature engineering of the data. Specifically, this should be any code that you use to generate new columns in the data frame `d`. Feature engineering that will be performed as part of an sklearn pipeline can be mentioned here but should be implemented in the following section.*\n",
    "\n",
    "*All code and figures should be accompanied by text that provides an overview / context to what is being done or presented.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be2b660e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      " RID              0\n",
      "ADAS13.bl        0\n",
      "ADAS13.m24       0\n",
      "AGE              0\n",
      "DX.bl            0\n",
      "PTGENDER         0\n",
      "PTEDUCAT         0\n",
      "PTETHCAT         0\n",
      "PTRACCAT         0\n",
      "PTMARRY          0\n",
      "APOE4            5\n",
      "Ventricles     147\n",
      "Hippocampus    147\n",
      "WholeBrain     148\n",
      "Entorhinal     147\n",
      "Fusiform       147\n",
      "MidTemp        147\n",
      "ICV              8\n",
      "dtype: int64\n",
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Summary of the data structure\n",
    "#print(d.info())\n",
    "#print(d.describe())\n",
    "\n",
    "# Checking for missing values\n",
    "missing_values = d.isnull().sum()\n",
    "print(\"Missing values per column:\\n\", missing_values)\n",
    "\n",
    "#重复值检查\n",
    "# Check duplicate rows\n",
    "duplicates = d.duplicated()\n",
    "\n",
    "# Count the number of duplicate rows\n",
    "num_duplicates = duplicates.sum()\n",
    "\n",
    "print(f\"Number of duplicate rows: {num_duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1eaa80a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical table of categorical variables: \n",
      "    Variable           Category Count  Percentage\n",
      "0      DX.bl               LMCI   367   35.356455\n",
      "1      DX.bl                 CN   334   32.177264\n",
      "2      DX.bl               EMCI   190   18.304432\n",
      "3      DX.bl                 AD   147   14.161850\n",
      "4   PTGENDER               Male   582   56.069364\n",
      "5   PTGENDER             Female   456   43.930636\n",
      "6   PTETHCAT    Not Hisp/Latino  1011   97.398844\n",
      "7   PTETHCAT        Hisp/Latino    21    2.023121\n",
      "8   PTETHCAT            Unknown     6    0.578035\n",
      "9   PTRACCAT              White   973   93.737958\n",
      "10  PTRACCAT              Black    35    3.371869\n",
      "11  PTRACCAT              Asian    16    1.541426\n",
      "12  PTRACCAT      More than one    10    0.963391\n",
      "13  PTRACCAT  Am Indian/Alaskan     2    0.192678\n",
      "14  PTRACCAT            Unknown     1    0.096339\n",
      "15  PTRACCAT  Hawaiian/Other PI     1    0.096339\n",
      "16   PTMARRY            Married   798   76.878613\n",
      "17   PTMARRY            Widowed   120   11.560694\n",
      "18   PTMARRY           Divorced    84    8.092486\n",
      "19   PTMARRY      Never married    31    2.986513\n",
      "20   PTMARRY            Unknown     5    0.481696\n",
      "21     APOE4                0.0   569   54.816956\n",
      "22     APOE4                1.0   370   35.645472\n",
      "23     APOE4                2.0    94    9.055877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhang\\AppData\\Local\\Temp\\ipykernel_47016\\2666474096.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  stats_table = pd.concat([stats_table, value_counts[['Variable', 'Category', 'Count', 'Percentage']]], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "category_columns = ['DX.bl', 'PTGENDER', 'PTETHCAT', 'PTRACCAT', 'PTMARRY', 'APOE4']\n",
    "\n",
    "stats_table = pd.DataFrame(columns=['Variable', 'Category', 'Count', 'Percentage'])\n",
    "\n",
    "# 遍历列并计算每个分类变量的值计数\n",
    "for col in category_columns:\n",
    "    value_counts = d[col].value_counts().rename_axis('Category').reset_index(name='Count')\n",
    "    value_counts['Variable'] = col  # 添加变量名称列\n",
    "    value_counts['Percentage'] = value_counts['Count'] / len(d) * 100  # 计算百分比\n",
    "    stats_table = pd.concat([stats_table, value_counts[['Variable', 'Category', 'Count', 'Percentage']]], ignore_index=True)\n",
    "\n",
    "# 调整列顺序\n",
    "stats_table = stats_table[['Variable', 'Category', 'Count', 'Percentage']]\n",
    "\n",
    "# 输出表格\n",
    "print(\"Statistical table of categorical variables: \")\n",
    "print(stats_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c04bc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7732a357",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['NewColumn_0'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Define the target and features (we will refine feature selection later)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mADAS13.m24\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNewColumn_0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mADAS13.m24\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Exclude person identifier and target(还有第一列的序号)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Drop rows with missing values (or consider imputation strategies)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m d_clean \u001b[38;5;241m=\u001b[39m d\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\Users\\zhang\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['NewColumn_0'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Define the target and features (we will refine feature selection later)\n",
    "target = 'ADAS13.m24'\n",
    "features = d.columns.drop(['RID', 'ADAS13.m24'])  # Exclude person identifier and target(还有第一列的序号)\n",
    "\n",
    "# Drop rows with missing values (or consider imputation strategies)\n",
    "d_clean = d.dropna().copy()\n",
    "'''\n",
    "d_clean = d.copy()\n",
    "n = list(d_clean.columns)\n",
    "\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "d_clean.iloc[:,[11,12,13,14,15,16,17,18]] = num_imputer.fit_transform(d_clean.iloc[:,[11,12,13,14,15,16,17,18]])\n",
    "'''\n",
    "# Create normalized volume features\n",
    "volume_cols = ['Ventricles', 'Hippocampus', 'WholeBrain', 'Entorhinal', 'Fusiform', 'MidTemp']\n",
    "for col in volume_cols:\n",
    "    new_col = col + '_norm'\n",
    "    d_clean.loc[:, new_col] = d_clean[col] / d_clean['ICV']\n",
    "\n",
    "# Verify the new columns\n",
    "print(d_clean[[col for col in d_clean.columns if '_norm' in col]].head())\n",
    "\n",
    "# Create training and testing sets\n",
    "train_df, test_df = train_test_split(d_clean, test_size=0.2, random_state=random_seed)\n",
    "print(\"Training set size:\", train_df.shape)\n",
    "print(\"Testing set size:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19a7697",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(d_clean[['ADAS13.m24', 'ADAS13.bl', 'AGE', 'PTEDUCAT', 'APOE4', 'Ventricles_norm', 'Hippocampus_norm', \n",
    "                      'WholeBrain_norm', 'Entorhinal_norm', 'Fusiform_norm', 'MidTemp_norm', 'ICV']])\n",
    "plt.suptitle(\"A pairwise diagram of the relationship between variables\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38ad4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_t = d_clean.copy().drop(columns=['NewColumn_0','RID'])\n",
    "numeric_df = d_t.select_dtypes(include=[np.number])\n",
    "corr_matrix = numeric_df.corr()\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b380ff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(d_clean[['ADAS13.m24', 'ADAS13.bl', 'AGE', 'Hippocampus_norm', 'WholeBrain_norm', 'Entorhinal_norm', 'Fusiform_norm','MidTemp_norm', 'ICV', \n",
    "                      'PTGENDER']], hue='PTGENDER')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa7f6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(d_clean[['ADAS13.m24', 'ADAS13.bl', 'AGE', 'Hippocampus_norm', 'WholeBrain_norm', 'Entorhinal_norm', 'Fusiform_norm','MidTemp_norm', 'ICV', \n",
    "                      'DX.bl']], hue='DX.bl')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6f9a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram for baseline ADAS-Cog 13 scores\n",
    "plt.figure()\n",
    "sns.histplot(d['ADAS13.bl'], bins=20, kde=True)\n",
    "plt.title('Distribution of Baseline ADAS-Cog 13 Scores')\n",
    "plt.xlabel('ADAS13.bl')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot of baseline vs. 24-month follow-up scores\n",
    "plt.figure()\n",
    "sns.scatterplot(x='ADAS13.bl', y='ADAS13.m24', data=d)\n",
    "plt.title('Baseline vs. 24-Month ADAS-Cog 13 Scores')\n",
    "plt.xlabel('ADAS13.bl')\n",
    "plt.ylabel('ADAS13.m24')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc9fe39",
   "metadata": {},
   "source": [
    "# Model Fitting and Tuning\n",
    "\n",
    "*In this section you should detail your choice of model and describe the process used to refine, tune, and fit that model. You are strongly encouraged to explore different models (e.g. linear regression, interaction terms, lasso, etc.) but you should not include a detailed narrative of all of these attempts. At most this section should briefly mention the methods explored and why they were rejected - most of your effort should go into describing the model you are using and your process for tuning and validating it.*\n",
    "\n",
    "*For example if you considered a linear regression model with interactions, a polynomial regression, and a lasso model and ultimately settled on the lasso approach then you should mention that other two approaches were tried but do not include any of the code or any in depth discussion of these models beyond why they were rejected. This section should then detail the development of the lasso model in terms of features used and additional tuning and validation which ultimately led to your final model.* \n",
    "\n",
    "*This section should also include the full implementation of your final model, including all necessary validation. As with figures, any included code must also be addressed in the text of the document.*\n",
    "\n",
    "*Finally, you should also provide comparison of your model with baseline linear regression model on the test data but only briefly describe the baseline model considered*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067eb28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a basic set of features for the baseline model\n",
    "baseline_features = ['ADAS13.bl', 'AGE', 'PTEDUCAT'] + [col for col in d_clean.columns if '_norm' in col]\n",
    "\n",
    "print(baseline_features)\n",
    "X_train_baseline = train_df[baseline_features]\n",
    "y_train = train_df[target]\n",
    "X_test_baseline = test_df[baseline_features]\n",
    "y_test = test_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631b260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the baseline model\n",
    "baseline_model = LinearRegression()\n",
    "baseline_model.fit(X_train_baseline, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_baseline = baseline_model.predict(X_test_baseline)\n",
    "baseline_mse = mean_squared_error(y_test, y_pred_baseline)\n",
    "print(\"Baseline Linear Regression MSE:\", baseline_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d515f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_names = baseline_model.feature_names_in_\n",
    "\n",
    "coefs = pd.DataFrame(\n",
    "    np.copy(baseline_model.coef_),\n",
    "    columns=[\"Coefficients\"],\n",
    "    index=fe_names,\n",
    ")\n",
    "\n",
    "print(coefs)\n",
    "\n",
    "coefs.plot.barh(figsize=(9, 7))\n",
    "plt.title(\"Linear regression\")\n",
    "plt.axvline(x=0, color=\".5\")\n",
    "plt.xlabel(\"Coefficient values\")\n",
    "plt.subplots_adjust(left=0.3)\n",
    "\n",
    "train_MSE, train_RMSE, train_R2 = model_fit(baseline_model, X_train_baseline, y_train, plot=True)\n",
    "print(f\"Training Data - MSE: {train_MSE}, RMSE: {train_RMSE}, R²: {train_R2}\")\n",
    "\n",
    "test_MSE, test_RMSE, test_R2 = model_fit(baseline_model, X_test_baseline, y_test, plot=True)\n",
    "print(f\"Test Data - MSE: {test_MSE}, RMSE: {test_RMSE}, R²: {test_R2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5163af12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#考虑性别分类\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "baseline_features_sex = ['PTGENDER', 'ADAS13.bl', 'AGE', 'PTEDUCAT'] + [col for col in d_clean.columns if '_norm' in col]\n",
    "\n",
    "X_train_baseline_sex = train_df[baseline_features_sex]\n",
    "y_train = train_df[target]\n",
    "X_test_baseline_sex = test_df[baseline_features_sex]\n",
    "y_test = test_df[target]\n",
    "\n",
    "cat_pre = OneHotEncoder(drop=np.array(['Female']))\n",
    "\n",
    "pipe_1 = Pipeline([\n",
    "    (\"pre_processing\", ColumnTransformer([\n",
    "        (\"cat_pre\", cat_pre, [0]), # Applied to sex\n",
    "        (\"num_pre\", 'passthrough', [1,2,3,4,5,6,7,8,9])])), \n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "\n",
    "pipe_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2399d4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "pipe_1.fit(X_train_baseline_sex, y_train)\n",
    "\n",
    "train_MSE, train_RMSE, train_R2 = model_fit(pipe_1, X_train_baseline_sex, y_train, plot=True)\n",
    "print(f\"Training Data - MSE: {train_MSE}, RMSE: {train_RMSE}, R²: {train_R2}\")\n",
    "\n",
    "test_MSE, test_RMSE, test_R2 = model_fit(pipe_1, X_test_baseline_sex, y_test, plot=True)\n",
    "print(f\"Test Data - MSE: {test_MSE}, RMSE: {test_RMSE}, R²: {test_R2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34b110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Poly(only interaction)\n",
    "cat_pre = OneHotEncoder(drop=np.array(['Female']))\n",
    "\n",
    "pf = PolynomialFeatures(interaction_only=True,include_bias=False)\n",
    "\n",
    "pipe_2 = Pipeline([\n",
    "    (\"pre_processing\", ColumnTransformer([\n",
    "        (\"cat_pre\", cat_pre, [0]),\n",
    "        (\"num_pre\", 'passthrough', [1,2,3,4,5,6,7,8,9])])),\n",
    "    (\"interact\", pf),\n",
    "    (\"model\", LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c109c920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "pipe_2.fit(X_train_baseline_sex, y_train)\n",
    "\n",
    "train_MSE, train_RMSE, train_R2 = model_fit(pipe_2, X_train_baseline_sex, y_train, plot=True)\n",
    "print(f\"Training Data - MSE: {train_MSE}, RMSE: {train_RMSE}, R²: {train_R2}\")\n",
    "\n",
    "test_MSE, test_RMSE, test_R2 = model_fit(pipe_2, X_test_baseline_sex, y_test, plot=True)\n",
    "print(f\"Test Data - MSE: {test_MSE}, RMSE: {test_RMSE}, R²: {test_R2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cb77c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Poly\n",
    "cat_pre = OneHotEncoder(drop=np.array(['Female']))\n",
    "\n",
    "pf = PolynomialFeatures(include_bias=False)\n",
    "\n",
    "poly_pipe = Pipeline([\n",
    "    (\"pre_processing\", ColumnTransformer([\n",
    "        (\"cat_pre\", cat_pre, [0]), \n",
    "        (\"poly\", pf, [1,2,3,4,5,6,7,8,9])])),\n",
    "    (\"model\", LinearRegression())])\n",
    "\n",
    "parameters = {\n",
    "    'pre_processing__poly__degree': np.arange(1,10,1)\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state=random_seed)\n",
    "\n",
    "grid_search = GridSearchCV(poly_pipe, parameters, cv = kf, scoring = 'neg_mean_squared_error', return_train_score=True).fit(X_train_baseline_sex, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d83284",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best index: \", grid_search.best_index_)\n",
    "print(\"best param: \", grid_search.best_params_)\n",
    "print(\"best score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d107719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MSE, train_RMSE, train_R2 = model_fit(grid_search, X_train_baseline_sex, y_train, plot=True)\n",
    "print(f\"Test Data - MSE: {test_MSE}, RMSE: {test_RMSE}, R²: {test_R2}\")\n",
    "\n",
    "test_MSE, test_RMSE, test_R2 = model_fit(grid_search, X_test_baseline_sex, y_test, plot=True)\n",
    "print(f\"Test Data - MSE: {test_MSE}, RMSE: {test_RMSE}, R²: {test_R2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a937dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = np.arange(1,10,1)\n",
    "fig, ax = plt.subplots(figsize=(9,7), ncols=1, nrows=1)\n",
    "plt.scatter(degree,-grid_search.cv_results_['mean_train_score'], color='k')\n",
    "plt.plot(degree,-grid_search.cv_results_['mean_train_score'], color='k', label='Mean Train MSE')\n",
    "plt.scatter(degree,-grid_search.cv_results_['mean_test_score'], color='r')\n",
    "plt.plot(degree,-grid_search.cv_results_['mean_test_score'], color='r', label='CV MSE')\n",
    "ax.legend()\n",
    "ax.set_xlabel('degree')\n",
    "ax.set_ylabel('MSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24da492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Grid of alpha values\n",
    "alphas = np.logspace(-2, 3, num=300) # from 10^-2 to 10^3\n",
    "\n",
    "ws = [] # Store coefficients\n",
    "mses_train = [] # Store training mses\n",
    "mses_test = [] # Store test mses\n",
    "\n",
    "for a in alphas:\n",
    "    m = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        Ridge(alpha=a)\n",
    "    ).fit(X_train_baseline, y_train)\n",
    "    \n",
    "    w_temp = np.copy(m[1].coef_)\n",
    "    ws.append(w_temp) \n",
    "    mses_train.append(mean_squared_error(y_train, m.predict(X_train_baseline)))\n",
    "    mses_test.append(mean_squared_error(y_test, m.predict(X_test_baseline)))\n",
    "\n",
    "# Create a data frame for plotting\n",
    "sol_path = pd.DataFrame(\n",
    "    data = ws,\n",
    "    columns = X_train_baseline.columns # Label columns w/ feature names\n",
    ").assign(\n",
    "    alpha = alphas,\n",
    ").melt(\n",
    "    id_vars = ('alpha')\n",
    ")\n",
    "\n",
    "# Plot solution path of the weights\n",
    "plt.figure(figsize=(10,6))\n",
    "ax = sns.lineplot(x='alpha', y='value', hue='variable', data=sol_path)\n",
    "ax.set_title(\"Ridge Coefficients\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4276165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid of tuning parameters\n",
    "alphas = np.logspace(-3, 2, num=300)  \n",
    "\n",
    "#Pipeline\n",
    "m = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        Ridge())\n",
    "\n",
    "# CV strategy\n",
    "cv = KFold(5, shuffle=True, random_state=random_seed)\n",
    "\n",
    "# Grid search\n",
    "gs = GridSearchCV(m,\n",
    "    param_grid={'ridge__alpha': alphas},\n",
    "    cv=cv,\n",
    "    scoring=\"neg_mean_squared_error\")\n",
    "gs.fit(X_train_baseline, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1358049",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs.best_params_)\n",
    "print(-gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4409a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit(gs.best_estimator_, X_test_baseline, y_test, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df79a1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only mean and split scores\n",
    "cv_mse = pd.DataFrame(\n",
    "    data = gs.cv_results_\n",
    ").filter(\n",
    "    # Extract the split#_test_score and mean_test_score columns\n",
    "    regex = '(split[0-9]+|mean)_test_score'\n",
    ").assign(\n",
    "    # Add the alphas as a column\n",
    "    alpha = alphas\n",
    ")\n",
    "\n",
    "cv_mse.update(\n",
    "    # Convert negative mses to positive\n",
    "    -1 * cv_mse.filter(regex = '_test_score')\n",
    ")\n",
    "\n",
    "# Plot CV MSE\n",
    "plt.figure(figsize=(10,6))\n",
    "ax = sns.lineplot(x='alpha', y='mean_test_score', data=cv_mse)\n",
    "ax.set_ylabel('CV MSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556a036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data frame for plotting\n",
    "d = cv_mse.melt(\n",
    "    id_vars=('alpha','mean_test_score'),\n",
    "    var_name='fold',\n",
    "    value_name='MSE'\n",
    ")\n",
    "\n",
    "# Plot the validation scores across folds\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.lineplot(x='alpha', y='MSE', color='black', errorbar=None, data = d)  # Plot the mean MSE in black.\n",
    "sns.lineplot(x='alpha', y='MSE', hue='fold', data = d) # Plot the curves for each fold in different colors\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037920a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso\n",
    "from sklearn.linear_model import Lasso\n",
    "alphas = np.linspace(0.01, 1, num=100) #We need smaller values of alpha in the grid\n",
    "\n",
    "ws = [] # Store coefficients\n",
    "mses_train = [] # Store training mses\n",
    "mses_test = [] # Store test mses\n",
    "\n",
    "for a in alphas:\n",
    "    m = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        Lasso(alpha=a)\n",
    "    ).fit(X_train_baseline, y_train)\n",
    "    \n",
    "    w_temp = np.copy(m[1].coef_)\n",
    "    ws.append(w_temp) \n",
    "    mses_train.append(mean_squared_error(y_train, m.predict(X_train_baseline)))\n",
    "    mses_test.append(mean_squared_error(y_test, m.predict(X_test_baseline)))\n",
    "\n",
    "# Create a data frame for plotting\n",
    "sol_path = pd.DataFrame(\n",
    "    data = ws,\n",
    "    columns = X_train_baseline.columns # Label columns w/ feature names\n",
    ").assign(\n",
    "    alpha = alphas,\n",
    ").melt(\n",
    "    id_vars = ('alpha')\n",
    ")\n",
    "\n",
    "# Plot solution path of the weights\n",
    "plt.figure(figsize=(10,6))\n",
    "ax = sns.lineplot(x='alpha', y='value', hue='variable', data=sol_path)\n",
    "ax.set_title(\"Lasso Coefficients\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee6ff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid of tuning parameters\n",
    "alphas = np.linspace(0.001, 1, num=100)\n",
    "\n",
    "#Pipeline\n",
    "m = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        Lasso())\n",
    "\n",
    "# CV strategy\n",
    "cv = KFold(5, shuffle=True, random_state=random_seed)\n",
    "\n",
    "# Grid search\n",
    "gs = GridSearchCV(m,\n",
    "    param_grid={'lasso__alpha': alphas},\n",
    "    cv=cv,\n",
    "    scoring=\"neg_mean_squared_error\")\n",
    "gs.fit(X_train_baseline, y_train)\n",
    "\n",
    "print(gs.best_params_)\n",
    "print(-gs.best_score_)\n",
    "\n",
    "model_fit(gs.best_estimator_, X_test_baseline, y_test, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4aa4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_mse = pd.DataFrame(\n",
    "    data = gs.cv_results_\n",
    ").filter(\n",
    "    # Extract the split#_test_score and mean_test_score columns\n",
    "    regex = '(split[0-9]+|mean)_test_score'\n",
    ").assign(\n",
    "    # Add the alphas as a column\n",
    "    alpha = alphas\n",
    ")\n",
    "\n",
    "cv_mse.update(\n",
    "    # Convert negative mses to positive\n",
    "    -1 * cv_mse.filter(regex = '_test_score')\n",
    ")\n",
    "plt.figure(figsize=(10,6))\n",
    "ax = sns.lineplot(x='alpha', y='mean_test_score', data=cv_mse)\n",
    "ax.set_ylabel('CV MSE')\n",
    "plt.show()\n",
    "\n",
    "d = cv_mse.melt(\n",
    "    id_vars=('alpha','mean_test_score'),\n",
    "    var_name='fold',\n",
    "    value_name='MSE'\n",
    ")\n",
    "\n",
    "# Plot the validation scores across folds\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.lineplot(x='alpha', y='MSE', color='black', errorbar=None, data = d)  # Plot the mean MSE in black.\n",
    "sns.lineplot(x='alpha', y='MSE', hue='fold', data = d) # Plot the curves for each fold in different colors\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6013c16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_l = GridSearchCV(\n",
    "    make_pipeline(\n",
    "        StandardScaler(),\n",
    "        LinearRegression()\n",
    "    ),\n",
    "    param_grid = {},\n",
    "    cv=KFold(5, shuffle=True, random_state=random_seed),\n",
    "    scoring=\"neg_mean_squared_error\"\n",
    ").fit(X_train_baseline, y_train)\n",
    "\n",
    "print('CV MSE for baseline linear model', round(gs_l.best_score_ * -1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b6067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Grid of tuning parameters\n",
    "alphas = np.linspace(0.001, 10, num=100)\n",
    "l1r = [0.01, .1, .5, .7, .9, .95, 1]\n",
    "\n",
    "# CV strategy\n",
    "cv = KFold(5, shuffle=True, random_state=random_seed)\n",
    "\n",
    "# Pipeline\n",
    "m = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        ElasticNet())\n",
    "\n",
    "# Grid search\n",
    "gs_enet = GridSearchCV(m,\n",
    "                        param_grid={'elasticnet__alpha': alphas, 'elasticnet__l1_ratio': l1r},\n",
    "                        cv = cv,\n",
    "                        scoring=\"neg_mean_squared_error\")\n",
    "gs_enet.fit(X_train_baseline, y_train)\n",
    "\n",
    "gs_enet.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f223bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CV MSE for elasticnet model', round(-gs_enet.best_score_,4))\n",
    "print('CV MSE for ridge model',round(-gs.best_score_,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886ea1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit(gs_enet.best_estimator_, X_test_baseline, y_test, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308a9c84",
   "metadata": {},
   "source": [
    "# Discussion & Conclusions\n",
    "\n",
    "*In this section you should provide a general overview of your final model, its performance, and reliability. You should discuss what the implications of your model are in terms of the included features, estimated parameters and relationships, predictive performance, and anything else you think is relevant.*\n",
    "\n",
    "*This should be written with a target audience of a health official or charity director, who is understands the pressing challenges associated with ageining and dementia but may only have university level mathematics (not necessarily postgraduate statistics or machine learning). Your goal should be to highlight to this audience how your model can useful. You should also mention potential limitations of your model.*\n",
    "\n",
    "*Finally, you should include recommendations on factors that may increase the risk of higher cognitive decline, which may be useful for identiying individuals that may benefit more from any proposed drugs or therapies.*\n",
    "\n",
    "*Keep in mind that a negative result, i.e. a model that does not work well predictively, that is well explained and justified in terms of why it failed will likely receive higher marks than a model with strong predictive performance but with poor or incorrect explinations / justifications.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb8539f",
   "metadata": {},
   "source": [
    "# Generative AI statement\n",
    "\n",
    "*Include a statement on how generative AI was used in the project and report.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09db6349",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "*Include references if any*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3625a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following to render to PDF\n",
    "!jupyter nbconvert --to pdf project1.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
